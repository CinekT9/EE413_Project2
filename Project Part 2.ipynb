{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cafa0cb-b6d7-49c4-968e-6e79572261de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Evaluation of ResNet18 and MobileNetV2 with Wavelet Compression\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pywt\n",
    "from torchvision.models import mobilenet_v2\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_dir = r\"C:\\Users\\HUAWEI\\Downloads\"\n",
    "data_dir = r\"C:\\Users\\HUAWEI\\Downloads\\mini-imagenet\\test\"  # Adjust to your dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73dcaa14-407f-4715-98d1-573d42e28220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Test Dataset\n",
    "# Transform for RGB images (3 channels, 84x84)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((84, 84)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Standard classification dataset for ResNet18 and MobileNetV2\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root))\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for cls in self.classes:\n",
    "            cls_path = os.path.join(root, cls)\n",
    "            if os.path.isdir(cls_path):\n",
    "                images = [os.path.join(cls_path, img) for img in os.listdir(cls_path) if img.endswith(('.jpg', '.png'))]\n",
    "                self.data.extend(images)\n",
    "                self.labels.extend([self.classes.index(cls)] * len(images))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# Load dataset\n",
    "classification_dataset = ClassificationDataset(root=data_dir, transform=transform)\n",
    "classification_loader = DataLoader(classification_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc133d1e-88ca-40de-972f-7abd377b2d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HUAWEI\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HUAWEI\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 loaded successfully.\n",
      "MobileNetV2 loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load Models\n",
    "# ResNet18\n",
    "resnet18 = models.resnet18(pretrained=False)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 100)  # Adjust for 100 classes\n",
    "try:\n",
    "    resnet18.load_state_dict(torch.load(os.path.join(model_dir, \"resnet18_finetuned.pth\"), map_location=device, weights_only=True))\n",
    "    print(\"ResNet18 loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading ResNet18: {e}\")\n",
    "    raise\n",
    "resnet18 = resnet18.to(device).eval()\n",
    "\n",
    "# MobileNetV2\n",
    "mobilenet_v2 = mobilenet_v2(pretrained=False)\n",
    "mobilenet_v2.classifier[1] = nn.Linear(mobilenet_v2.classifier[1].in_features, 100)  # Adjust for 100 classes\n",
    "try:\n",
    "    mobilenet_v2.load_state_dict(torch.load(os.path.join(model_dir, \"mobilenet_v2_finetuned.pth\"), map_location=device, weights_only=True))\n",
    "    print(\"MobileNetV2 loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading MobileNetV2: {e}\")\n",
    "    raise\n",
    "mobilenet_v2 = mobilenet_v2.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0692c17-467b-4e85-8a68-af6dfe479258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Wavelet-Based Image Compression\n",
    "import numpy as np\n",
    "import pywt\n",
    "import torch\n",
    "\n",
    "def apply_wavelet_compression(images, retain):\n",
    "    \"\"\"\n",
    "    Apply wavelet compression to a batch of images.\n",
    "    \n",
    "    Args:\n",
    "        images (torch.Tensor): Input images [N, 3, 84, 84]\n",
    "        retain (float): Percentage of wavelet coefficients to retain (e.g., 0.1 for 10%)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Compressed images [N, 3, 84, 84]\n",
    "        float: PSNR (dB)\n",
    "        float: Compression ratio\n",
    "    \"\"\"\n",
    "    images_np = images.cpu().numpy()  # [N, 3, 84, 84]\n",
    "    compressed = []\n",
    "    total_coeffs = 0\n",
    "    retained_coeffs = 0\n",
    "    \n",
    "    for img in images_np:\n",
    "        img_recon = np.zeros_like(img)  # [3, 84, 84]\n",
    "        for c in range(3):  # Process R, G, B channels\n",
    "            # 2-level wavelet decomposition\n",
    "            coeffs = pywt.wavedec2(img[c], 'db1', level=2)\n",
    "            coeff_arr, coeff_slices = pywt.coeffs_to_array(coffs)\n",
    "            total_coeffs += coeff_arr.size\n",
    "            \n",
    "            # Threshold to retain top 'retain' percentage of coefficients\n",
    "            thresh = np.percentile(np.abs(coeff_arr), 100 * (1 - retain))\n",
    "            coeff_arr[np.abs(coeff_arr) < thresh] = 0\n",
    "            retained_coeffs += np.sum(coeff_arr != 0)\n",
    "            \n",
    "            # Reconstruct image\n",
    "            coeffs_recon = pywt.array_to_coeffs(coeff_arr, coeff_slices, output_format='wavedec2')\n",
    "            img_recon[c] = pywt.waverec2(coeffs_recon, 'db1')\n",
    "        \n",
    "        compressed.append(img_recon)\n",
    "    \n",
    "    # Stack compressed images\n",
    "    compressed = np.stack(compressed)  # [N, 3, 84, 84]\n",
    "    \n",
    "    # Compute compression ratio\n",
    "    comp_ratio = total_coeffs / retained_coeffs if retained_coeffs > 0 else 1\n",
    "    \n",
    "    # Compute PSNR\n",
    "    mse = np.mean((images_np - compressed) ** 2)\n",
    "    psnr = 10 * np.log10(1 / mse) if mse > 0 else 100\n",
    "    \n",
    "    # Convert compressed images to tensor\n",
    "    compressed = torch.from_numpy(compressed).to(images.device).float()\n",
    "    \n",
    "    return compressed, psnr, comp_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d6af918-4b51-4394-8968-79bdc4f1ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define Evaluation Function\n",
    "def apply_wavelet_compression(images, retain):\n",
    "    images_np = images.cpu().numpy()  # [N, 3, 84, 84]\n",
    "    compressed = []\n",
    "    total_coeffs = 0\n",
    "    retained_coeffs = 0\n",
    "    for img in images_np:\n",
    "        img_recon = np.zeros_like(img)\n",
    "        for c in range(3):\n",
    "            coeffs = pywt.wavedec2(img[c], 'db1', level=2)\n",
    "            coeff_arr, coeff_slices = pywt.coeffs_to_array(coeffs)\n",
    "            total_coeffs += coeff_arr.size\n",
    "            thresh = np.percentile(np.abs(coeff_arr), 100 * (1 - retain))\n",
    "            coeff_arr[np.abs(coeff_arr) < thresh] = 0\n",
    "            retained_coeffs += np.sum(coeff_arr != 0)\n",
    "            coeffs_recon = pywt.array_to_coeffs(coeff_arr, coeff_slices, output_format='wavedec2')\n",
    "            img_recon[c] = pywt.waverec2(coeffs_recon, 'db1')\n",
    "        compressed.append(img_recon)\n",
    "    compressed = np.stack(compressed)\n",
    "    comp_ratio = total_coeffs / retained_coeffs if retained_coeffs > 0 else 1\n",
    "    mse = np.mean((images_np - compressed) ** 2)\n",
    "    psnr = 10 * np.log10(1 / mse) if mse > 0 else 100\n",
    "    return torch.from_numpy(compressed).to(device).float(), psnr, comp_ratio\n",
    "\n",
    "def evaluate_classification(model, dataloader, device, retain_percentage):\n",
    "    model.eval()\n",
    "    accuracies = []\n",
    "    psnr_values = []\n",
    "    compression_ratios = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)  # [batch_size, 3, 84, 84]\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Compress images\n",
    "            images_comp, psnr, comp_ratio = apply_wavelet_compression(images, retain_percentage)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images_comp)  # [batch_size, 100]\n",
    "            predictions = outputs.argmax(dim=1)  # [batch_size]\n",
    "            \n",
    "            # Compute accuracy\n",
    "            accuracy = (predictions == labels).float().mean().item()\n",
    "            accuracies.append(accuracy)\n",
    "            psnr_values.append(psnr)\n",
    "            compression_ratios.append(comp_ratio)\n",
    "    \n",
    "    acc_mean = np.mean(accuracies)\n",
    "    acc_std = np.std(accuracies)\n",
    "    psnr_val = np.mean(psnr_values)\n",
    "    comp_ratio = np.mean(compression_ratios)\n",
    "    return acc_mean, acc_std, psnr_val, comp_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c0e46bf-4661-44b5-b98d-b30b6abf986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ResNet18 with 10.0% coefficients retained:\n",
      "ResNet18 - Accuracy: 0.0123 ± 0.0527, PSNR: 19.93 dB, Compression Ratio: 9.98\n",
      "\n",
      "Evaluating ResNet18 with 25.0% coefficients retained:\n",
      "ResNet18 - Accuracy: 0.0149 ± 0.0621, PSNR: 26.93 dB, Compression Ratio: 3.99\n",
      "\n",
      "Evaluating ResNet18 with 50.0% coefficients retained:\n",
      "ResNet18 - Accuracy: 0.0144 ± 0.0588, PSNR: 36.15 dB, Compression Ratio: 2.00\n",
      "\n",
      "Evaluating MobileNetV2 with 10.0% coefficients retained:\n",
      "MobileNetV2 - Accuracy: 0.0223 ± 0.0921, PSNR: 19.93 dB, Compression Ratio: 9.98\n",
      "\n",
      "Evaluating MobileNetV2 with 25.0% coefficients retained:\n",
      "MobileNetV2 - Accuracy: 0.0163 ± 0.0632, PSNR: 26.93 dB, Compression Ratio: 3.99\n",
      "\n",
      "Evaluating MobileNetV2 with 50.0% coefficients retained:\n",
      "MobileNetV2 - Accuracy: 0.0139 ± 0.0543, PSNR: 36.15 dB, Compression Ratio: 2.00\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Run Evaluations\n",
    "results = {\n",
    "    'resnet18': {'classification': {}},\n",
    "    'mobilenet_v2': {'classification': {}}\n",
    "}\n",
    "retain_percentages = [0.1, 0.25, 0.5]\n",
    "\n",
    "# Evaluate ResNet18\n",
    "for retain in retain_percentages:\n",
    "    print(f\"\\nEvaluating ResNet18 with {retain*100}% coefficients retained:\")\n",
    "    acc_mean, acc_std, psnr_val, comp_ratio = evaluate_classification(resnet18, classification_loader, device, retain)\n",
    "    results['resnet18']['classification'][retain] = {\n",
    "        'accuracy_mean': acc_mean,\n",
    "        'accuracy_std': acc_std,\n",
    "        'psnr': psnr_val,\n",
    "        'compression_ratio': comp_ratio\n",
    "    }\n",
    "    print(f\"ResNet18 - Accuracy: {acc_mean:.4f} ± {acc_std:.4f}, PSNR: {psnr_val:.2f} dB, Compression Ratio: {comp_ratio:.2f}\")\n",
    "\n",
    "# Evaluate MobileNetV2\n",
    "for retain in retain_percentages:\n",
    "    print(f\"\\nEvaluating MobileNetV2 with {retain*100}% coefficients retained:\")\n",
    "    acc_mean, acc_std, psnr_val, comp_ratio = evaluate_classification(mobilenet_v2, classification_loader, device, retain)\n",
    "    results['mobilenet_v2']['classification'][retain] = {\n",
    "        'accuracy_mean': acc_mean,\n",
    "        'accuracy_std': acc_std,\n",
    "        'psnr': psnr_val,\n",
    "        'compression_ratio': comp_ratio\n",
    "    }\n",
    "    print(f\"MobileNetV2 - Accuracy: {acc_mean:.4f} ± {acc_std:.4f}, PSNR: {psnr_val:.2f} dB, Compression Ratio: {comp_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94b71e31-d7e5-429d-b26f-4985a8ed6308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to compression_results.md\n",
      "\n",
      "Summary:\n",
      "\n",
      "Retaining 10.0% Coefficients:\n",
      "ResNet18 - Accuracy: 0.0123 ± 0.0527, PSNR: 19.93 dB, Compression Ratio: 9.98\n",
      "MobileNetV2 - Accuracy: 0.0223 ± 0.0921, PSNR: 19.93 dB, Compression Ratio: 9.98\n",
      "\n",
      "Retaining 25.0% Coefficients:\n",
      "ResNet18 - Accuracy: 0.0149 ± 0.0621, PSNR: 26.93 dB, Compression Ratio: 3.99\n",
      "MobileNetV2 - Accuracy: 0.0163 ± 0.0632, PSNR: 26.93 dB, Compression Ratio: 3.99\n",
      "\n",
      "Retaining 50.0% Coefficients:\n",
      "ResNet18 - Accuracy: 0.0144 ± 0.0588, PSNR: 36.15 dB, Compression Ratio: 2.00\n",
      "MobileNetV2 - Accuracy: 0.0139 ± 0.0543, PSNR: 36.15 dB, Compression Ratio: 2.00\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save and Display Results\n",
    "base_dir = r\"C:\\Users\\HUAWEI\\Downloads\"\n",
    "with open(os.path.join(base_dir, \"compression_results.md\"), \"w\") as f:\n",
    "    f.write(\"# Wavelet-based Image Compression Results\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Standard Classification (ResNet18)\\n\")\n",
    "    for retain in retain_percentages:\n",
    "        f.write(f\"### Retaining {retain*100}% Coefficients\\n\")\n",
    "        f.write(\"- Accuracy (Mean ± Std): {:.4f} ± {:.4f}\\n\".format(\n",
    "            results['resnet18']['classification'][retain]['accuracy_mean'],\n",
    "            results['resnet18']['classification'][retain]['accuracy_std']))\n",
    "        f.write(f\"- PSNR: {results['resnet18']['classification'][retain]['psnr']:.2f} dB\\n\")\n",
    "        f.write(f\"- Compression Ratio: {results['resnet18']['classification'][retain]['compression_ratio']:.2f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Standard Classification (MobileNetV2)\\n\")\n",
    "    for retain in retain_percentages:\n",
    "        f.write(f\"### Retaining {retain*100}% Coefficients\\n\")\n",
    "        f.write(\"- Accuracy (Mean ± Std): {:.4f} ± {:.4f}\\n\".format(\n",
    "            results['mobilenet_v2']['classification'][retain]['accuracy_mean'],\n",
    "            results['mobilenet_v2']['classification'][retain]['accuracy_std']))\n",
    "        f.write(f\"- PSNR: {results['mobilenet_v2']['classification'][retain]['psnr']:.2f} dB\\n\")\n",
    "        f.write(f\"- Compression Ratio: {results['mobilenet_v2']['classification'][retain]['compression_ratio']:.2f}\\n\\n\")\n",
    "\n",
    "print(\"\\nResults saved to compression_results.md\")\n",
    "print(\"\\nSummary:\")\n",
    "for retain in retain_percentages:\n",
    "    print(f\"\\nRetaining {retain*100}% Coefficients:\")\n",
    "    print(f\"ResNet18 - Accuracy: {results['resnet18']['classification'][retain]['accuracy_mean']:.4f} ± \"\n",
    "          f\"{results['resnet18']['classification'][retain]['accuracy_std']:.4f}, \"\n",
    "          f\"PSNR: {results['resnet18']['classification'][retain]['psnr']:.2f} dB, \"\n",
    "          f\"Compression Ratio: {results['resnet18']['classification'][retain]['compression_ratio']:.2f}\")\n",
    "    print(f\"MobileNetV2 - Accuracy: {results['mobilenet_v2']['classification'][retain]['accuracy_mean']:.4f} ± \"\n",
    "          f\"{results['mobilenet_v2']['classification'][retain]['accuracy_std']:.4f}, \"\n",
    "          f\"PSNR: {results['mobilenet_v2']['classification'][retain]['psnr']:.2f} dB, \"\n",
    "          f\"Compression Ratio: {results['mobilenet_v2']['classification'][retain]['compression_ratio']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
