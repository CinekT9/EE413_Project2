{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f121c3",
   "metadata": {},
   "source": [
    "# This is fine tuning on compressed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a32ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and basic definitions\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pywt\n",
    "from torchvision.models import mobilenet_v2\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_dir = r\"\"\n",
    "data_dir = r\".\\mini-imagenet\"  # Adjust to your dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53fa8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of wavelet compression from part 2\n",
    "def apply_wavelet_compression(images, retain):\n",
    "    images_np = images.cpu().numpy()  # [N, 3, 84, 84]\n",
    "    compressed = []\n",
    "    total_coeffs = 0\n",
    "    retained_coeffs = 0\n",
    "    for img in images_np:\n",
    "        img_recon = np.zeros_like(img)\n",
    "        for c in range(3):\n",
    "            coeffs = pywt.wavedec2(img[c], 'db1', level=2)\n",
    "            coeff_arr, coeff_slices = pywt.coeffs_to_array(coeffs)\n",
    "            total_coeffs += coeff_arr.size\n",
    "            thresh = np.percentile(np.abs(coeff_arr), 100 * (1 - retain))\n",
    "            coeff_arr[np.abs(coeff_arr) < thresh] = 0\n",
    "            retained_coeffs += np.sum(coeff_arr != 0)\n",
    "            coeffs_recon = pywt.array_to_coeffs(coeff_arr, coeff_slices, output_format='wavedec2')\n",
    "            img_recon[c] = pywt.waverec2(coeffs_recon, 'db1')\n",
    "        compressed.append(img_recon)\n",
    "    compressed = np.stack(compressed)\n",
    "    comp_ratio = total_coeffs / retained_coeffs if retained_coeffs > 0 else 1\n",
    "    mse = np.mean((images_np - compressed) ** 2)\n",
    "    psnr = 10 * np.log10(1 / mse) if mse > 0 else 100\n",
    "    return torch.from_numpy(compressed).to(device).float(), psnr, comp_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f257ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and Modify the Model\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "mobilenet_v2 = models.mobilenet_v2(num_classes=100, pretrained=True)\n",
    "mobilenet_v2.classifier[1] = torch.nn.Linear(mobilenet_v2.classifier[1].in_features, 1280)\n",
    "# Move to appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = mobilenet_v2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1841117",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root=os.path.join(data_dir, \"train\"), transform=transform)\n",
    "val_dataset = ImageFolder(root=os.path.join(data_dir, \"val\"), transform=transform)\n",
    "test_dataset = ImageFolder(root=os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)  # num_workers=0 for local\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c01464e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "#Training loop\n",
    "for epoch in range(10): # loop over the dataset multiple times\n",
    "\n",
    " running_loss = 0.0\n",
    " for i, data in enumerate(train_loader, 0):\n",
    " \n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    images_comp, psnr, comp_ratio = apply_wavelet_compression(inputs, 0.25) #25% compression\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(images_comp)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "        (epoch + 1, i + 1, running_loss / 2000))\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "#This code is adapted from the following guide https://toxigon.com/fine-tuning-pre-trained-models-with-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33987d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"compressed_trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2cf9661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 uncompressed test images: 1 %\n",
      "Accuracy of the network on the 10000 compressed test images: 1 %\n"
     ]
    }
   ],
   "source": [
    "def eval_model(compr):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 uncompressed test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            images_comp, psnr, comp_ratio = apply_wavelet_compression(inputs, compr) #25% compression\n",
    "            outputs = model(images_comp)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 compressed test images: %d %%' % (100 * correct / total))\n",
    "#This code is adapted from the following guide https://toxigon.com/fine-tuning-pre-trained-models-with-pytorch\n",
    "\n",
    "eval_model(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd66a7",
   "metadata": {},
   "source": [
    "### While the accuracy of mobilevnet2 trained on compressed images is extremely poor at 1%, it is better than the mobilenetv2 trained on uncompressed images (0.37%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6452ed12",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
